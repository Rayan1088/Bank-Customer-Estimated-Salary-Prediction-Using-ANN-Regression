{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepossing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le_gender = LabelEncoder()\n",
    "df['Gender'] = le_gender.fit_transform(df['Gender'])\n",
    "    \n",
    "# One-hot encode Geography\n",
    "geo_encoder = OneHotEncoder(sparse_output=False)\n",
    "geo_encoded = geo_encoder.fit_transform(df['Geography'].values.reshape(-1, 1))\n",
    "geo_df = pd.DataFrame(geo_encoded, columns=['France', 'Germany', 'Spain'])\n",
    "df = pd.concat([df.drop('Geography', axis=1), geo_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save The Encoded Data In Pickle File :\n",
    "with open('lable_Encoding_gender.pkl','wb') as file:\n",
    "    pickle.dump(le_gender,file)\n",
    "    \n",
    "with open('One_Hot_Encoding_Geography.pkl','wb') as file:\n",
    "    pickle.dump(geo_encoder,file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>146466.46</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7969</th>\n",
       "      <td>637</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>108204.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>545</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>779</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>691</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>116927.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "5189          826       1   41       5  146466.46              2          0   \n",
       "7969          637       1   49       2  108204.52              1          1   \n",
       "9039          545       0   44       1       0.00              2          1   \n",
       "5208          779       0   38       7       0.00              2          1   \n",
       "506           691       1   30       7  116927.89              1          1   \n",
       "\n",
       "      IsActiveMember  Exited  France  Germany  Spain  \n",
       "5189               0       0     0.0      0.0    1.0  \n",
       "7969               0       1     0.0      1.0    0.0  \n",
       "9039               1       0     0.0      0.0    1.0  \n",
       "5208               1       0     0.0      0.0    1.0  \n",
       "506                0       0     0.0      1.0    0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split The Data Into Train & Test :\n",
    "X=df.drop(['EstimatedSalary'],axis=1)\n",
    "y=df['EstimatedSalary']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=50)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization (or z-score normalization) of the features data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the StandardScaler object in pickle file\n",
    "os.makedirs('artifacts', exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open('artifacts/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, nodes, layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        layers_list = [\n",
    "            nn.Linear(input_dim, nodes),\n",
    "            nn.BatchNorm1d(nodes),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ]\n",
    "        \n",
    "        # Hidden layers\n",
    "        current_nodes = nodes\n",
    "        for _ in range(layers):\n",
    "            next_nodes = max(current_nodes // 2, 64)\n",
    "            layers_list.extend([\n",
    "                nn.Linear(current_nodes, next_nodes),\n",
    "                nn.BatchNorm1d(next_nodes),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            current_nodes = next_nodes\n",
    "        \n",
    "        # Output layer\n",
    "        layers_list.append(nn.Linear(current_nodes, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Optuna Object Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    layers = trial.suggest_int('layers', 1, 10)\n",
    "    nodes = trial.suggest_categorical('nodes', [128, 256, 512])\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    X_train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(X_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Model, loss\n",
    "    model = SalaryPredictor(X_train.shape[1], nodes, layers, dropout_rate)  # Fixed parameter order\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Optimizer Selection\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if total_loss / len(train_loader) < 1e-4:\n",
    "            break\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.FloatTensor(X_test)\n",
    "        y_val_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "        val_predictions = model(X_val_tensor)\n",
    "        val_loss = nn.functional.mse_loss(val_predictions, y_val_tensor)\n",
    "    \n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:26:02,937] A new study created in memory with name: no-name-d9e35582-faee-4e64-bfc5-2854392e2a47\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\mrray\\AppData\\Local\\Temp\\ipykernel_11632\\531971730.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "Best trial: 0. Best value: 1.32682e+10:   5%|▌         | 1/20 [00:15<04:49, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:26:18,161] Trial 0 finished with value: 13268209664.0 and parameters: {'layers': 4, 'nodes': 512, 'epochs': 20, 'learning_rate': 0.00111719501851434, 'dropout_rate': 0.2935822604542264, 'batch_size': 128, 'optimizer': 'Adam', 'weight_decay': 1.0995743047712087e-05}. Best is trial 0 with value: 13268209664.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  10%|█         | 2/20 [00:43<06:52, 22.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:26:46,462] Trial 1 finished with value: 3339330816.0 and parameters: {'layers': 1, 'nodes': 512, 'epochs': 20, 'learning_rate': 0.008973549805486144, 'dropout_rate': 0.24011218896979006, 'batch_size': 32, 'optimizer': 'RMSprop', 'weight_decay': 0.00015342300377368197}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  15%|█▌        | 3/20 [04:50<35:26, 125.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:30:53,097] Trial 2 finished with value: 12714425344.0 and parameters: {'layers': 10, 'nodes': 128, 'epochs': 40, 'learning_rate': 0.00034171418740720425, 'dropout_rate': 0.46468075456310165, 'batch_size': 16, 'optimizer': 'RMSprop', 'weight_decay': 0.00022812762762608346}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  20%|██        | 4/20 [05:16<22:58, 86.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:31:19,550] Trial 3 failed with parameters: {'layers': 7, 'nodes': 512, 'epochs': 30, 'learning_rate': 0.0001837787278768557, 'dropout_rate': 0.44484694421779514, 'batch_size': 128, 'optimizer': 'SGD', 'weight_decay': 2.5457475388042588e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:31:19,555] Trial 3 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  25%|██▌       | 5/20 [05:28<14:53, 59.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:31:31,926] Trial 4 finished with value: 13326066688.0 and parameters: {'layers': 6, 'nodes': 128, 'epochs': 10, 'learning_rate': 0.00021807130019130713, 'dropout_rate': 0.42745896062708133, 'batch_size': 64, 'optimizer': 'Adam', 'weight_decay': 2.5057255682277814e-05}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  30%|███       | 6/20 [06:00<11:41, 50.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:32:03,663] Trial 5 finished with value: 13265260544.0 and parameters: {'layers': 8, 'nodes': 512, 'epochs': 20, 'learning_rate': 0.0008194594374104536, 'dropout_rate': 0.49964729833528343, 'batch_size': 64, 'optimizer': 'RMSprop', 'weight_decay': 1.421948392855858e-05}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  35%|███▌      | 7/20 [06:11<08:05, 37.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:32:14,753] Trial 6 finished with value: 11210125312.0 and parameters: {'layers': 4, 'nodes': 512, 'epochs': 10, 'learning_rate': 0.008326790937436022, 'dropout_rate': 0.1674788927341025, 'batch_size': 64, 'optimizer': 'RMSprop', 'weight_decay': 1.9392719865247568e-05}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  40%|████      | 8/20 [08:30<13:56, 69.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:34:33,796] Trial 7 finished with value: 13202585600.0 and parameters: {'layers': 3, 'nodes': 128, 'epochs': 50, 'learning_rate': 0.00012749336186290973, 'dropout_rate': 0.22798781644871588, 'batch_size': 16, 'optimizer': 'RMSprop', 'weight_decay': 6.61012452361262e-05}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  45%|████▌     | 9/20 [08:52<10:01, 54.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:34:55,302] Trial 8 failed with parameters: {'layers': 4, 'nodes': 512, 'epochs': 30, 'learning_rate': 0.0004396108078038496, 'dropout_rate': 0.2492002809107571, 'batch_size': 64, 'optimizer': 'SGD', 'weight_decay': 4.467987891758455e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:34:55,308] Trial 8 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  50%|█████     | 10/20 [10:46<12:09, 72.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:36:49,080] Trial 9 finished with value: 4223362816.0 and parameters: {'layers': 9, 'nodes': 512, 'epochs': 30, 'learning_rate': 0.004608742601028917, 'dropout_rate': 0.38293447146604476, 'batch_size': 32, 'optimizer': 'RMSprop', 'weight_decay': 0.00015914962239967927}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  55%|█████▌    | 11/20 [11:06<08:32, 56.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:37:09,896] Trial 10 failed with parameters: {'layers': 4, 'nodes': 256, 'epochs': 20, 'learning_rate': 0.007651393143002524, 'dropout_rate': 0.21550613833749332, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 0.0003434964475429778} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:37:09,900] Trial 10 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  60%|██████    | 12/20 [12:48<09:25, 70.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:38:51,864] Trial 11 finished with value: 13296114688.0 and parameters: {'layers': 8, 'nodes': 128, 'epochs': 50, 'learning_rate': 0.00011669501687259122, 'dropout_rate': 0.2671207319070979, 'batch_size': 32, 'optimizer': 'RMSprop', 'weight_decay': 0.0006851340341955975}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  65%|██████▌   | 13/20 [12:53<05:54, 50.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:38:56,617] Trial 12 failed with parameters: {'layers': 8, 'nodes': 256, 'epochs': 10, 'learning_rate': 0.00043135397691161116, 'dropout_rate': 0.38667789519722506, 'batch_size': 128, 'optimizer': 'SGD', 'weight_decay': 3.735686979238252e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:38:56,620] Trial 12 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  70%|███████   | 14/20 [13:02<03:49, 38.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 22:39:05,890] Trial 13 finished with value: 13314283520.0 and parameters: {'layers': 3, 'nodes': 256, 'epochs': 20, 'learning_rate': 0.0005563245699748222, 'dropout_rate': 0.4109444590190595, 'batch_size': 128, 'optimizer': 'RMSprop', 'weight_decay': 0.0002648646079107434}. Best is trial 1 with value: 3339330816.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  75%|███████▌  | 15/20 [13:22<02:42, 32.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:39:25,409] Trial 14 failed with parameters: {'layers': 1, 'nodes': 256, 'epochs': 30, 'learning_rate': 0.0025734566729838718, 'dropout_rate': 0.11316564284974656, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 5.6939397894507956e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:39:25,413] Trial 14 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  80%|████████  | 16/20 [13:42<01:54, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:39:45,038] Trial 15 failed with parameters: {'layers': 1, 'nodes': 256, 'epochs': 30, 'learning_rate': 0.002903560378269382, 'dropout_rate': 0.11443463665591375, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 5.946123400814716e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:39:45,045] Trial 15 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  85%|████████▌ | 17/20 [14:00<01:16, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:40:03,094] Trial 16 failed with parameters: {'layers': 1, 'nodes': 256, 'epochs': 30, 'learning_rate': 0.0023314228237976344, 'dropout_rate': 0.10013639926351786, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 6.427408404553757e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:40:03,097] Trial 16 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  90%|█████████ | 18/20 [14:19<00:47, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:40:22,711] Trial 17 failed with parameters: {'layers': 1, 'nodes': 256, 'epochs': 30, 'learning_rate': 0.0019515600563334212, 'dropout_rate': 0.10360150316820588, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 6.249189240570181e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:40:22,716] Trial 17 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09:  95%|█████████▌| 19/20 [14:41<00:22, 22.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:40:44,000] Trial 18 failed with parameters: {'layers': 1, 'nodes': 256, 'epochs': 30, 'learning_rate': 0.0020042535104264707, 'dropout_rate': 0.10319424795273621, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 5.59542837590734e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:40:44,006] Trial 18 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.33933e+09: 100%|██████████| 20/20 [14:59<00:00, 44.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-01-24 22:41:02,592] Trial 19 failed with parameters: {'layers': 1, 'nodes': 256, 'epochs': 30, 'learning_rate': 0.0026805257494689734, 'dropout_rate': 0.1066447448934231, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 6.171048270313787e-05} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-01-24 22:41:02,595] Trial 19 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study object and optimize it\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True) \n",
    "# Increased trials for better optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model training and saving\n",
    "best_params = study.best_params\n",
    "best_model = SalaryPredictor(\n",
    "    X_train.shape[1], \n",
    "    best_params['nodes'], \n",
    "    best_params['layers'], \n",
    "    best_params['dropout_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'layers': 1, 'nodes': 512, 'epochs': 20, 'learning_rate': 0.008973549805486144, 'dropout_rate': 0.24011218896979006, 'batch_size': 32, 'optimizer': 'RMSprop', 'weight_decay': 0.00015342300377368197}\n",
      "Best validation loss: 3339330816.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best validation loss:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model state\n",
    "torch.save(best_model.state_dict(), 'Best_ANN_regression_model.h5')\n",
    "# It allow to Preserve the model's learned parameters for future use \n",
    "# without having to retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best hyperparameters in a pickle file\n",
    "with open('Best_Hyperparameters.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the study object\n",
    "with open('study.pkl', 'wb') as f:\n",
    "    pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model in onnx format\n",
    "# dummy_input = torch.randn(1, X_train.shape[1])\n",
    "# torch.onnx.export(best_model, dummy_input, 'Best_ANN_regression_model.onnx', verbose=True)\n",
    "\n",
    "# Save the best model in torchscript format\n",
    "# traced_model = torch.jit.trace(best_model, dummy_input)\n",
    "# traced_model.save('Best_ANN_regression_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
